{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce2f051",
   "metadata": {},
   "source": [
    "# Guidelines for Prompting\n",
    "In this lesson, you'll practice two prompting principles and their related tactics in order to write effective prompts for large language models.\n",
    "\n",
    "\n",
    "1. Basic Prompts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf1086",
   "metadata": {},
   "source": [
    "#### Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "393d0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86170a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"): # Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff4e711",
   "metadata": {},
   "source": [
    "I need to remember some rules before we start:\n",
    "\n",
    "Use delimiters to clearly indicate distinct parts of the input \n",
    "\n",
    "Delimiters can be anything like: ```, \"\"\", < >, <tag> </tag>, :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b316d",
   "metadata": {},
   "source": [
    "### 1.Basic Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7071fd5",
   "metadata": {},
   "source": [
    "You can get very good results using ordinary prompts, but when you need more specific results or want to make sure our prompt serves your purposes, you should improve your prompt quality.\n",
    "\n",
    "Let's see this with examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c070e",
   "metadata": {},
   "source": [
    "##### Complete your sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6dac3d5",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my best to accomplish my goals and make progress towards my dreams.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\" Complete this sentence:\n",
    "```Today I will do```\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8eb0ff",
   "metadata": {},
   "source": [
    "#### Summarize your text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7263b6e3",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT is an AI-powered chatbot that has been developed to provide users with an interactive and engaging experience. The development process of ChatGPT has been a long and complex journey that has involved a team of experts in the field of artificial intelligence, machine learning, and natural language processing.\n",
      "\n",
      "The first step in the development process was to gather data from various sources, including social media platforms, online forums, and customer service interactions. This data was then used to train the chatbot to understand and respond to user queries in a natural and conversational manner.\n",
      "\n",
      "The next step was to develop the algorithms that would enable ChatGPT to analyze user queries and provide relevant responses. This involved creating a complex system of rules and decision trees that would allow the chatbot to understand the context of each query and provide accurate and helpful responses.\n",
      "\n",
      "Once the algorithms were in place, the team began testing the chatbot to identify any issues or areas for improvement. This involved conducting extensive user testing and gathering feedback from users to ensure that the chatbot was meeting their needs and expectations.\n",
      "\n",
      "Throughout the development process, the team also focused on ensuring that ChatGPT was user-friendly and easy to use. This involved designing an intuitive interface that would allow users to interact with the chatbot in a natural and seamless way.\n",
      "\n",
      "Overall, the development process of ChatGPT has been a challenging but rewarding journey. The team has worked tirelessly to create a chatbot that is intelligent, responsive, and user-friendly, and they are confident that it will provide users with an exceptional experience.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Write a text about ChatGPT developing process.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7400ac3e",
   "metadata": {
    "height": 455
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT is an AI-powered chatbot that has been developed through a complex process involving data gathering, algorithm development, user testing, and user-friendly interface design to provide users with an interactive and engaging experience.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "ChatGPT is an AI-powered chatbot that has been developed to provide users with an interactive and engaging experience.\n",
    "The development process of ChatGPT has been a long and complex journey that has involved a team of experts in the field of artificial intelligence, machine learning, and natural language processing.\n",
    "\n",
    "The first step in the development process was to gather data from various sources, including social media platforms, online forums, and customer service interactions. \n",
    "This data was then used to train the chatbot to understand and respond to user queries in a natural and conversational manner.\n",
    "\n",
    "The next step was to develop the algorithms that would enable ChatGPT to analyze user queries and provide relevant responses. \n",
    "This involved creating a complex system of rules and decision trees that would allow the chatbot to understand the context of each query and provide accurate and helpful responses.\n",
    "\n",
    "Once the algorithms were in place, the team began testing the chatbot to identify any issues or areas for improvement.\n",
    "This involved conducting extensive user testing and gathering feedback from users to ensure that the chatbot was meeting their needs and expectations.\n",
    "\n",
    "Throughout the development process, the team also focused on ensuring that ChatGPT was user-friendly and easy to use. \n",
    "This involved designing an intuitive interface that would allow users to interact with the chatbot in a natural and seamless way.\n",
    "\n",
    "Overall, the development process of ChatGPT has been a challenging but rewarding journey. \n",
    "The team has worked tirelessly to create a chatbot that is intelligent, responsive, and user-friendly, and they are confident that it will provide users with an exceptional experience.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3744fe9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6218bf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details, or email support@openai.com if you have any questions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m\n\u001b[0;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124mYou should express what you want a model to do by \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m \u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124mproviding instructions that are as clear and \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m \u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124mmore detailed and relevant outputs.\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     13\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124mSummarize the text delimited by triple backticks \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m \u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124minto a single sentence.\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m```\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m```\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m, in \u001b[0;36mget_completion\u001b[1;34m(prompt, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_completion\u001b[39m(prompt, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m): \u001b[38;5;66;03m# Andrew mentioned that the prompt/ completion paradigm is preferable for this class\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[1;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# this is the degree of randomness of the model's output\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:149\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[0;32m    141\u001b[0m         timeout,\n\u001b[0;32m    142\u001b[0m         stream,\n\u001b[0;32m    143\u001b[0m         headers,\n\u001b[0;32m    144\u001b[0m         request_timeout,\n\u001b[0;32m    145\u001b[0m         typed_api_type,\n\u001b[0;32m    146\u001b[0m         requestor,\n\u001b[0;32m    147\u001b[0m         url,\n\u001b[0;32m    148\u001b[0m         params,\n\u001b[1;32m--> 149\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__prepare_create_request(\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[0;32m    153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:106\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[1;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    104\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m MAX_TIMEOUT\n\u001b[1;32m--> 106\u001b[0m requestor \u001b[38;5;241m=\u001b[39m \u001b[43mapi_requestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIRequestor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    115\u001b[0m     deployment_id,\n\u001b[0;32m    116\u001b[0m     engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m     params,\n\u001b[0;32m    125\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_requestor.py:130\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[1;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    123\u001b[0m     key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     organization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    128\u001b[0m ):\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_base \u001b[38;5;241m=\u001b[39m api_base \u001b[38;5;129;01mor\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mapi_base\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    132\u001b[0m         ApiType\u001b[38;5;241m.\u001b[39mfrom_str(api_type)\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m api_type\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m ApiType\u001b[38;5;241m.\u001b[39mfrom_str(openai\u001b[38;5;241m.\u001b[39mapi_type)\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_version \u001b[38;5;241m=\u001b[39m api_version \u001b[38;5;129;01mor\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mapi_version\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[1;34m()\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mapi_key\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mAuthenticationError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo API key provided. You can set your API key in code using \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai.api_key = <API-KEY>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai.api_key_path = <PATH>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details, or email support@openai.com if you have any questions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m     )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details, or email support@openai.com if you have any questions."
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c6cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365577c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b928c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87857393-6369-4b66-87c9-5f3253edf28e",
   "metadata": {},
   "source": [
    "# Summarizing\n",
    "In this lesson, you will summarize text with a focus on specific topics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac673e1",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv, find_dotenv\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66de8ca6",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"): # Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387b0686-bea6-41a2-b879-88721dc0ec10",
   "metadata": {},
   "source": [
    "## Text to summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce2cf3c",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "prod_review = \"\"\"\n",
    "Got this panda plush toy for my daughter's birthday, \\\n",
    "who loves it and takes it everywhere. It's soft and \\ \n",
    "super cute, and its face has a friendly look. It's \\ \n",
    "a bit small for what I paid though. I think there \\ \n",
    "might be other options that are bigger for the \\ \n",
    "same price. It arrived a day earlier than expected, \\ \n",
    "so I got to play with it myself before I gave it \\ \n",
    "to her.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d95eba0-7744-491a-a30a-8ee687303b7a",
   "metadata": {},
   "source": [
    "## Summarize with a word/sentence/character limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3023c6",
   "metadata": {
    "height": 251
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft and cute panda plush toy loved by daughter, but a bit small for the price. Arrived early.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90832908-3b3a-459b-b595-bbe15c2a72fa",
   "metadata": {},
   "source": [
    "## Summarize with a focus on shipping and delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850bdd2",
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site to give feedback to the \\\n",
    "Shipping deparmtment. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words, and focusing on any aspects \\\n",
    "that mention shipping and delivery of the product. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01204385-1d27-420c-80ee-bd4b524550f6",
   "metadata": {},
   "source": [
    "## Summarize with a focus on price and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d865432",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site to give feedback to the \\\n",
    "pricing deparmtment, responsible for determining the \\\n",
    "price of the product.  \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words, and focusing on any aspects \\\n",
    "that are relevant to the price and perceived value. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a561c4-d9a0-48a8-86c4-725746fb08df",
   "metadata": {},
   "source": [
    "#### Comment\n",
    "- Summaries include topics that are not related to the topic of focus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aff99cd-dc09-467c-bd09-897ffe06a232",
   "metadata": {},
   "source": [
    "## Try \"extract\" instead of \"summarize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190943b0",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to extract relevant information from \\ \n",
    "a product review from an ecommerce site to give \\\n",
    "feedback to the Shipping department. \n",
    "\n",
    "From the review below, delimited by triple quotes \\\n",
    "extract the information relevant to shipping and \\ \n",
    "delivery. Limit to 30 words. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f513da2e-f89c-4c91-8456-b79c630e70c9",
   "metadata": {},
   "source": [
    "## Summarize multiple product reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027822c2",
   "metadata": {
    "height": 1288
   },
   "outputs": [],
   "source": [
    "\n",
    "review_1 = prod_review \n",
    "\n",
    "# review for a standing lamp\n",
    "review_2 = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one \\\n",
    "had additional storage and not too high of a price \\\n",
    "point. Got it fast - arrived in 2 days. The string \\\n",
    "to the lamp broke during the transit and the company \\\n",
    "happily sent over a new one. Came within a few days \\\n",
    "as well. It was easy to put together. Then I had a \\\n",
    "missing part, so I contacted their support and they \\\n",
    "very quickly got me the missing piece! Seems to me \\\n",
    "to be a great company that cares about their customers \\\n",
    "and products. \n",
    "\"\"\"\n",
    "\n",
    "# review for an electric toothbrush\n",
    "review_3 = \"\"\"\n",
    "My dental hygienist recommended an electric toothbrush, \\\n",
    "which is why I got this. The battery life seems to be \\\n",
    "pretty impressive so far. After initial charging and \\\n",
    "leaving the charger plugged in for the first week to \\\n",
    "condition the battery, I've unplugged the charger and \\\n",
    "been using it for twice daily brushing for the last \\\n",
    "3 weeks all on the same charge. But the toothbrush head \\\n",
    "is too small. I’ve seen baby toothbrushes bigger than \\\n",
    "this one. I wish the head was bigger with different \\\n",
    "length bristles to get between teeth better because \\\n",
    "this one doesn’t.  Overall if you can get this one \\\n",
    "around the $50 mark, it's a good deal. The manufactuer's \\\n",
    "replacements heads are pretty expensive, but you can \\\n",
    "get generic ones that're more reasonably priced. This \\\n",
    "toothbrush makes me feel like I've been to the dentist \\\n",
    "every day. My teeth feel sparkly clean! \n",
    "\"\"\"\n",
    "\n",
    "# review for a blender\n",
    "review_4 = \"\"\"\n",
    "So, they still had the 17 piece system on seasonal \\\n",
    "sale for around $49 in the month of November, about \\\n",
    "half off, but for some reason (call it price gouging) \\\n",
    "around the second week of December the prices all went \\\n",
    "up to about anywhere from between $70-$89 for the same \\\n",
    "system. And the 11 piece system went up around $10 or \\\n",
    "so in price also from the earlier sale price of $29. \\\n",
    "So it looks okay, but if you look at the base, the part \\\n",
    "where the blade locks into place doesn’t look as good \\\n",
    "as in previous editions from a few years ago, but I \\\n",
    "plan to be very gentle with it (example, I crush \\\n",
    "very hard items like beans, ice, rice, etc. in the \\ \n",
    "blender first then pulverize them in the serving size \\\n",
    "I want in the blender then switch to the whipping \\\n",
    "blade for a finer flour, and use the cross cutting blade \\\n",
    "first when making smoothies, then use the flat blade \\\n",
    "if I need them finer/less pulpy). Special tip when making \\\n",
    "smoothies, finely cut and freeze the fruits and \\\n",
    "vegetables (if using spinach-lightly stew soften the \\ \n",
    "spinach then freeze until ready for use-and if making \\\n",
    "sorbet, use a small to medium sized food processor) \\ \n",
    "that you plan to use that way you can avoid adding so \\\n",
    "much ice if at all-when making your smoothie. \\\n",
    "After about a year, the motor was making a funny noise. \\\n",
    "I called customer service but the warranty expired \\\n",
    "already, so I had to buy another one. FYI: The overall \\\n",
    "quality has gone done in these types of products, so \\\n",
    "they are kind of counting on brand recognition and \\\n",
    "consumer loyalty to maintain sales. Got it in about \\\n",
    "two days.\n",
    "\"\"\"\n",
    "\n",
    "reviews = [review_1, review_2, review_3, review_4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c39cc8",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "for i in range(len(reviews)):\n",
    "    prompt = f\"\"\"\n",
    "    Your task is to generate a short summary of a product \\ \n",
    "    review from an ecommerce site. \n",
    "\n",
    "    Summarize the review below, delimited by triple \\\n",
    "    backticks in at most 20 words. \n",
    "\n",
    "    Review: ```{reviews[i]}```\n",
    "    \"\"\"\n",
    "\n",
    "    response = get_completion(prompt)\n",
    "    print(i, response, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c9f921-8672-4124-bad6-8bee65078ccb",
   "metadata": {},
   "source": [
    "## Try experimenting on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05d8a20-86f2-4613-835e-41c49a504b5b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
